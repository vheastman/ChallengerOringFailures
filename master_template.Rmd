---
title: "Lab 1 VHE"
author: "Victoria Eastman"
date: "September 19, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Initial EDA

Problem statement: 

```{r}
# Import libraries
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(Hmisc))

setwd("/Users/gurditchahal/w271_lab1")
data <- read.csv("challenger.csv")
```

```{r}
glimpse(data)
describe(data)

# I'm curious about the value counts for o-ring failures
table(data$O.ring)
```

Initial findings:

  - 23 data points with no missing values for any variables
  - Dependent variable, O.ring, is categorical and takes three values: 0, 1, and 2 representing the number of o-ring failures on space launches. The mean value is 0.3913 which means the data is skewed towards 0 o-ring failures. Futher investigation shows there were 2 flights with 2 o-ring failures, 5 with 1 failure, and 16 with no failures.
  - The explanatory variables are as follows:
  
    + Temp: temperature at launch (degrees F)
    + Pressure: Combustion pression (psi)
    
    -Although pressure (in psi) is generally expected to be a continuous variable, we see three consistent values of   50,100,200 and may be considered as a categorical variable instead.
    
    
  
  
```{r}
par(mfrow = c(3,2))

# histogram of explanatory variables
for (i in 2:4){
  hist(as.numeric(data[,i]), main=paste0("Histogram of ", colnames(data)[i]), xlab=NA)
  hist(as.numeric(log(data[,i])), main=paste0("Histogram of log(", colnames(data)[i], ")"), xlab=NA)
}

```



```{r}
for (i in 2:3){
  print(ggplot(data, aes(factor(O.ring), data[,i])) +
          geom_boxplot(aes(fill = factor(O.ring))) + 
          geom_jitter() +
          ggtitle(paste0(colnames(data)[i], " by Admit")) + 
          theme(plot.title = element_text(lineheight=1, face="bold")))
}
```
```{r}
#how much does temperature vary by each pressure stage
ggplot(data, aes(factor(Pressure), Temp)) +
          geom_boxplot(aes(fill = factor(Pressure))) + 
          geom_jitter() +
          ggtitle( "Temperature by Pressure") + 
          theme(plot.title = element_text(lineheight=1, face="bold"))
```

```{r}
#How do failures vary by pressure level?
ggplot(data,aes(x=factor(O.ring)))+geom_histogram(stat='count')+facet_grid(~Pressure)
```

```{r}
#What does the distribution of temperatures look like?
ggplot(data, aes(x = Temp)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.2, fill="#0072B2", colour="black") +
  ggtitle("Temperature") + 
  theme(plot.title = element_text(lineheight=1, face="bold"))



```

```{r}
ggplot(data, aes(x = factor(O.ring), y = Temp, fill = factor(O.ring))) + geom_boxplot() +
facet_wrap(~ Pressure, ncol = 3)
```

```{r}
plot(O.ring~Temp,data=data)
```



####Introduction to problem and model###

###EDA###

###Model Selection and Rationale###

###Conclusion###


4.The failure of an O-ring on the space shuttle Challenger’s booster rockets led to its destruction in 1986. Using data on previous space shuttle launches, Dalal et al. (1989) examine the probability of an O-ring failure as a function of temperature at launch and combustion pressure. Data from their paper is included in the challenger.csv file.

Below are the variables:
•Flight:Flightnumber
•Temp:Temperature(F) at launch
•Pressure: Combustion pressure (psi)
•O.ring:Number of primary field O-ringfailures
•Number:Total number of primary field O-rings(six total,three each for the two booster rockets)
The response variable is O.ring,and the explanatory variables are Temp and Pressure. 
Complete the following:

(a)The authors use logistic regression to estimate the probability an O-ring will fail.In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors’ concerns about independence.

*This independence assumption is necessary for deriving the likelihood-based solution as we can take products of the probabilities. Potential issues is that the quality/durability of the O-ring might be dependent on the factory or even batch that it came from (clustering) and could interfere with producing a more accurate estimate when left unaccounted for. Moreover damage in one O-ring could affect the probability of damage in subsequent O-rings (might be easier for the system to collapse as a whole). *

(b)Estimate the logistic regression model using the explanatory variables in a linear form.

```{r}
df$O.ring[df$O.ring==2]<-1 # need to reformulate to at least one failure
mod.fit1<-glm(formula=O.ring~Pressure+Temp,data=df,family=binomial(link = logit))
summary(mod.fit1)
```


(c)Perform LRTs to judge the importance of the explanatory variables in the model.
```{r}
Anova(mod.fit1,Test='LRT')
```


(d)The authors chose to remove Pressure from the model based on the LRTs. Based on your results, discuss why you think this was done. Are there any potential problems with removing this variable?

In terms of statistical significance, pressure wasn't found to be statistically significant. Potential problems could be losing precision on temp as well as in probability, especially for edge cases.

5.Continuing Exercise 4, consider the simplified model $$logit(\pi)=Beta_0+Beta_1*Temp$$, where $$\pi$$ is the probability of an O-ring failure. Complete the following:

(a)Estimate the model.
```{r}
mod.fit2<-glm(formula=O.ring~Temp,data=df,family=binomial(link = logit))
summary(mod.fit2)
```


(b)Construct two plots: (1)$$\pi$$ vs.Temp and (2) Expected number of failures vs.Temp. Use a temperature range of 31 to 81 on the x-axis even though the minimumtemperature in the data set was 53.
```{r}
w<-aggregate(formula=O.ring~Temp,data=df,FUN=sum)
n<-aggregate(formula=O.ring~Temp,data=df,FUN=length)
w.n<-data.frame(Temperature=w$Temp,Failure=w$O.ring,trials = n$O.ring, proportion = round(w$O.ring/n$O.ring,4))
head(w.n)
```

```{r}
plot(x=w$Temp,y=w$O.ring/n$O.ring,xlab="Temp(F)", ylab = "Estimated probability", panel.first =grid(col = "gray", lty = "dotted"))
curve(expr=predict(object=mod.fit2,newdata=data.frame(Temp = x), type = "response"), col = "red", add=TRUE,xlim=c(31,81))
```
```{r}
#Todo:Expected number of failures vs.Temp.
```


(c)Include the 95% Wald confidence interval bands for $$\pi$$ on the plot. Why are the bands much wider for lower temperatures than for higher temperatures?

```{r}
plot(x=w$Temp,y=w$O.ring/n$O.ring,xlab="Temp(F)", ylab = "Estimated probability", panel.first =grid(col = "gray", lty = "dotted"))
curve(expr=predict(object=mod.fit2,newdata=data.frame(Temp = x), type = "response"), col = "red", add=TRUE,xlim=c(31,81))

ci.pi<-function(newdata,mod.fit.obj,alpha){linear.pred <- predict(object = mod.fit.obj, newdata =newdata, type = "link", se = TRUE)
CI.lin.pred.lower <- linear.pred$fit - qnorm(p =1-alpha/2)*linear.pred$se
CI.lin.pred.upper <- linear.pred$fit + qnorm(p =1-alpha/2)*linear.pred$se

CI.pi.lower <- exp(CI.lin.pred.lower) / (1 +exp(CI.lin.pred.lower))
CI.pi.upper <- exp(CI.lin.pred.upper) / (1 +exp(CI.lin.pred.upper))
list(lower = CI.pi.lower, upper = CI.pi.upper)}

curve(expr=ci.pi(newdata=data.frame(Temp=x),mod.fit.obj = mod.fit2, alpha = 0.05)$lower, col = "blue", lty="dotdash",add=TRUE,xlim=c(31,81))

curve(expr=ci.pi(newdata=data.frame(Temp=x),mod.fit.obj = mod.fit2, alpha = 0.05)$upper, col = "blue", lty="dotdash",add=TRUE,xlim=c(31,81))



```
Bands are wider due to change in probability across temperature gradient. Much steeper drop in temperature below and above 65 (similar to complete separation problem). Less of a drastic change in higher temperatures due to two "middle" values between 70 and 75.

(d)The temperature was 31 at launch for the Challenger in 1986. Estimate theprobability of an O-ring failure using this temperature, and compute a corresponding confidence interval.  Discuss what assumptions need to be made in order to apply the inference procedures.

```{r}
alpha=0.05
predict.data <- data.frame(Temp=31) #data to predict on

linear.pred=predict(object = mod.fit2, newdata = predict.data, #linear part of model
                      type = "link", se = TRUE)

pi.hat = exp(linear.pred$fit)/(1+exp(linear.pred$fit)) #estimated probability
pi.hat

CI.lin.pred = linear.pred$fit + qnorm(p = c(alpha/2, 1-alpha/2))*linear.pred$se #confidence interval before exponentiation



CI.pi = exp(CI.lin.pred)/(1+exp(CI.lin.pred)) #actual interval
CI.pi
```


(e)Rather than using Wald or profile LR intervals for the probability of failure, Dalalet al. (1989) use a parametric bootstrap to compute intervals. Their process was to (1) simulate a large number of data sets (n= 23 for each) from the estimated model of $$logit(\pi)=\beta_{0}+\beta_{1}*Temp$$;(2)estimate new models for each dataset,say $$logit(\pi)=Beta_{0}+Beta_{1}*Temp$$;and (3)compute at a specific temperature of interest. The authors used the 0.05 and 0.95 observed quantiles from the simulated distribution as their 90% confidence interval limits. Using the parametric bootstrap, compute 90% confidence intervals separately at temperatures of 31 and 72.27

```{r}
#Todo: Bootstrapping CI
```


(f)Determine if a quadratic term is needed in the model for the temperature.

```{r}
mod.fit.Ha<-glm(formula=O.ring~Temp+I(Temp^2),data=df,family=binomial(link = logit))
anova(mod.fit2,mod.fit.Ha,test="Chisq")
```

Quadratic term fails to produce significant effect in change in residual deviance and so we fail to reject that the coefficient is actually 0 for the quadratic term.
